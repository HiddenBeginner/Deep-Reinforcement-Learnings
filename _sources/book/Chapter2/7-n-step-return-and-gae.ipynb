{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Advantage Estimation\n",
    "\n",
    "REINFORCE까지는 대부분의 많은 강화학습 책이나 강화학습 강의에서 다룬다. \n",
    "하지만, REINFORCE까지만 공부한 상태로 심층강화학습 논문을 읽기 시작하면, \n",
    "자신이 공부한 내용이랑 많이 다르다는 것을 뼈저리게 느낄 수 있을 것이다.\n",
    "이제부터 슬슬 심층강화학습 논문들을 읽을 때 필요한 기술과 지식에 대해서 다뤄볼 예정이다. \n",
    "\n",
    "<br>\n",
    "\n",
    "그 중 가장 먼저 다룰 내용은 Ganeralized Advatange Estimation (GAE)이다. 참고할 논문의 정보는 다음과 같다.\n",
    "\n",
    "- 제목: High-Dimensional Continuous Control Using Generalized Advantage Estimation\n",
    "- 저자: Schulman, John, Philipp Moritz, Sergey Levine, Michael I. Jordan, and Pieter Abbeel, ***Berkeley***\n",
    "- 학회: ICLR 2016\n",
    "- 링크: http://arxiv.org/abs/1506.02438\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient 및 REINFORCE 복습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
