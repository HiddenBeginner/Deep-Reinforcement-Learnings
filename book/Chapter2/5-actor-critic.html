
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>10. Actor-critic 알고리즘 &#8212; 심층강화학습</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "HiddenBeginner/Deep-Reinforcement-Learnings");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/HDBG.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="참고문헌" href="../Reference.html" />
    <link rel="prev" title="9. REINFORCE with baseline" href="4-reinforce-with-baseline.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FTQEC31PV8"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-FTQEC31PV8');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/HDBG.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">심층강화학습</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    심층강화학습 (Deep Reinforcement Learnings)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Markov Decision Process
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1/1-sequential-decision-making-problems.html">
   1. 순차적 의사 결정 문제, 에이전트, 환경
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1/2-markov-decision-processes.html">
   2. Markov Decision Process (MDP)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1/3-policy-return-value.html">
   3. 정책, Return, 가치 함수
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1/4-bellman-equation.html">
   4. 벨만 방정식: 가치 함수의 재귀적 성질
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter1/5-stochastic-approximation.html">
   5. 가치 함수 근사하기: Stochastic approximation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Policy gradient methods
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1-policy-gradient-theorem.html">
   6. Policy Gradient Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-reinforce.html">
   7. REINFORCE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-implementation-reinforce.html">
   8. REINFORCE 구현
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4-reinforce-with-baseline.html">
   9. REINFORCE with baseline
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   10. Actor-critic 알고리즘
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  참고문헌
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Reference.html">
   참고문헌
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/hiddenbeginner/Deep-Reinforcement-Learnings"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/hiddenbeginner/Deep-Reinforcement-Learnings/issues/new?title=Issue%20on%20page%20%2Fbook/Chapter2/5-actor-critic.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/book/Chapter2/5-actor-critic.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reinforce-with-baseline">
   10.1. REINFORCE with baseline 복습
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-actor-critic">
   10.2. Online actor-critic 알고리즘
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Actor-critic 알고리즘</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reinforce-with-baseline">
   10.1. REINFORCE with baseline 복습
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-actor-critic">
   10.2. Online actor-critic 알고리즘
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="actor-critic">
<h1><span class="section-number">10. </span>Actor-critic 알고리즘<a class="headerlink" href="#actor-critic" title="Permalink to this headline">#</a></h1>
<section id="reinforce-with-baseline">
<h2><span class="section-number">10.1. </span>REINFORCE with baseline 복습<a class="headerlink" href="#reinforce-with-baseline" title="Permalink to this headline">#</a></h2>
<p>이전 장에서는 상태가치함수를 베이스라인으로 사용하여 policy gradient을 분산을 줄여주었다.</p>
<div class="math notranslate nohighlight" id="equation-policy-gradient-baseline">
<span class="eqno">(10.1)<a class="headerlink" href="#equation-policy-gradient-baseline" title="Permalink to this equation">#</a></span>\[\nabla_{\mathbf{\theta}} J(\mathbf{\theta}) \propto \sum_{s \in \mathcal{S}} d_{\pi_{\mathbf{\theta}}}(s) \sum_{a \in \mathcal{A}} \left( Q^{\pi_{\mathbf{\theta}}}(s,a) - V^{\pi_{\mathbf{\theta}}}(s) \right) \nabla_{\mathbf{\theta}} \pi_{\mathbf{\theta}}(a|s).\]</div>
<br>
<p>위에서 상태가치함수와 행동가치함수를 직접 구할 수 없기 때문에 행동가치함수를 대신하여 시뮬레이션을 통해 얻은 return <span class="math notranslate nohighlight">\(G_t\)</span>를 사용했고,
상태가치함수는 뉴럴 네트워크 <span class="math notranslate nohighlight">\(V_\phi\)</span>를 사용하여 근사시켰다. 그래서 우리는 다음과 같은 policy gradient의 추정치를 얻었다.</p>
<div class="math notranslate nohighlight" id="equation-reinforce-baseline-gradient">
<span class="eqno">(10.2)<a class="headerlink" href="#equation-reinforce-baseline-gradient" title="Permalink to this equation">#</a></span>\[\nabla_{\theta} J(\theta) \approx \hat{g} := \frac{1}{T} \sum\limits_{t=0}^{T-1}\left( G_t - V_{\phi}(s_t)\right) \nabla_{\mathbf{\theta}} \log \pi_{\mathbf{\theta}}(a_t | s_t).\]</div>
<br>
</section>
<hr class="docutils" />
<section id="online-actor-critic">
<h2><span class="section-number">10.2. </span>Online actor-critic 알고리즘<a class="headerlink" href="#online-actor-critic" title="Permalink to this headline">#</a></h2>
<p>Policy gradient theorem를 사용하는 방법론들 중 정책과 가치함수 모두를 뉴럴 네트워크로 모델링하는 방법론들을 Actor-critic 방법론이라고 부른다.
여기서 actor (배우)는 정책 네트워크를 의미하며 critic (비평가)는 actor의 행동을 평가하는 가치 네트워크를 말한다.
배우-비평가 방법론이라고 부르기에는 조금 오글거리기 때문에 앞으로 actor-critic 방법론으로 부를 것이다.
하지만 REINFORCE with baseline 알고리즘은 정책과 상태가치함수를 모두 뉴럴 네트워크로 근사시키지만 actor-critic 알고리즘이라고 부르지 않는다.
그 이유에 대해서는 다양한 의견이 있지만,
필자의 생각은 식 <a class="reference internal" href="#equation-policy-gradient-baseline">(10.1)</a>에서 베이스라인 부분이 아닌 <span class="math notranslate nohighlight">\(Q^{\pi_{\mathbf{\theta}}}(s,a)\)</span>를 추정하기 위하여 가치 네트워크가 사용될 때만 actor-critic 알고리즘이라고 부르는 것 같다.
REINFORCE with baseline은 <span class="math notranslate nohighlight">\(Q^{\pi_{\mathbf{\theta}}}(s,a)\)</span>의 추정치로 return <span class="math notranslate nohighlight">\(G_t\)</span>를 사용했고, 가치 네트워크 <span class="math notranslate nohighlight">\(V_\phi\)</span>는 베이스라인으로만 사용되었기 때문에 actor-critic 방법론으로 분류되지 않는다.</p>
<br>
<p>그럼 <span class="math notranslate nohighlight">\(Q^{\pi_{\mathbf{\theta}}}(s,a)\)</span>를 추정하기 위해 뉴럴 네트워크를 사용하면 actor-critic 방법론이 될 것이다.
하지만 베이스라인과 함께 사용한다고 하면 행동가치함수를 위한 네트워크 <span class="math notranslate nohighlight">\(Q_{\psi}(s, a)\)</span>와 상태가치함수를 위한 네트워크 <span class="math notranslate nohighlight">\(V_{\phi}(s)\)</span> 2개의 네트워크를 학습시켜야 하기 때문에 학습 안정성 측면에서 안 좋을 것이다. 그래서 우리는 다음과 같은 행동가치함수의 성질을 사용할 것이다. 아래 식은 실제 상태가치함수 및 행동가치함수에 대해서 성립한다. 증명은 식 <a class="reference internal" href="../Chapter1/4-bellman-equation.html#equation-action-bellman-equation1">(4.5)</a>에서 찾아볼 수 있다.</p>
<div class="math notranslate nohighlight">
\[Q^{\pi}(s, a)= r(s, a) + \gamma \mathbb{E}_{s' \sim p(\cdot|s,a)}\left[ V^{\pi}(s')\right] \; \text{ for all } \; s \in \mathcal{S}, a \in \mathcal{A}.\]</div>
<br>
<p>따라서 가치 네트워크 <span class="math notranslate nohighlight">\(V_\phi\)</span>를 사용해서 실제 행동가치함수를 추정할 수 있다.</p>
<div class="math notranslate nohighlight">
\[Q^{\pi}(s, a) \approx r(s, a) + \gamma \mathbb{E}_{s' \sim p(\cdot|s,a)}\left[ V_{\theta}(s') \right].\]</div>
<br>
<p>물론 정확한 기댓값을 구하기 어렵기 때문에 하나의 샘플로 기댓값을 대체할 것이다. 환경과 상호작용하여 얻은 <span class="math notranslate nohighlight">\(t\)</span> 시점의 데이터 (transition) <span class="math notranslate nohighlight">\((s_t, a_t, r_t, s_{t+1})\)</span>를 사용하여 행동가치함수를 근사시킨다. <span class="math notranslate nohighlight">\(s_{t+1}\)</span>가 전이 확률 분포 <span class="math notranslate nohighlight">\(p(\cdot|s_t, a_t)\)</span>로부터 샘플링되었기 때문에 기댓값에 대한 점 추정치로 사용될 수 있는 것이다.</p>
<div class="math notranslate nohighlight" id="equation-actor-critic-td-target">
<span class="eqno">(10.3)<a class="headerlink" href="#equation-actor-critic-td-target" title="Permalink to this equation">#</a></span>\[Q^{\pi}(s_t, a_t) \approx r_t + \gamma  V_{\theta}(s_{t+1}).\]</div>
<br>
<p>이제 식 <a class="reference internal" href="#equation-reinforce-baseline-gradient">(10.2)</a>에서 행동가치함수의 추정치로 사용된 <span class="math notranslate nohighlight">\(G_t\)</span> 대신 식 <a class="reference internal" href="#equation-actor-critic-td-target">(10.3)</a>을 대입해보자.</p>
<div class="math notranslate nohighlight" id="equation-actor-critic-batch-gradient">
<span class="eqno">(10.4)<a class="headerlink" href="#equation-actor-critic-batch-gradient" title="Permalink to this equation">#</a></span>\[\nabla_{\theta} J(\theta) \approx \hat{g}_{\text{batch}} := \frac{1}{T} \sum\limits_{t=0}^{T-1}\left( r_t + \gamma  V_{\theta}(s_{t+1}) - V_{\phi}(s_t)\right) \nabla_{\mathbf{\theta}} \log \pi_{\mathbf{\theta}}(a_t | s_t).\]</div>
<br>
<p>식 <a class="reference internal" href="#equation-actor-critic-batch-gradient">(10.4)</a>의 그레디언트 추정치를 사용하는 것도 하나의 actor-critic 알고리즘으로 볼 수 있다.
하지만 식 <a class="reference internal" href="#equation-actor-critic-batch-gradient">(10.4)</a>에는 REINFORCE 알고리즘의 잔재가 남아 있다.
REINFORCE의 경우 return <span class="math notranslate nohighlight">\(G_t\)</span>을 계산하기 위하여 환경의 초기 상태부터 시작하여 상호작용이 종료될 때까지 trajectory <span class="math notranslate nohighlight">\((s_0, a_0, r_0, s_1, a_1, r_1,\ldots, s_T)\)</span>를 수집하고 네트워크 업데이트가 이뤄졌다. <span class="math notranslate nohighlight">\(G_t\)</span>를 계산할 때 <span class="math notranslate nohighlight">\(t\)</span>시점 이후로 받은 모든 보상을 더하기 때문이다.
하지만, 식 <a class="reference internal" href="#equation-actor-critic-batch-gradient">(10.4)</a>은 환경이 종료될 때까지 기다릴 필요 없이 매 시점 <span class="math notranslate nohighlight">\(t\)</span>마다 환경과 상호작용하여 얻은 데이터 <span class="math notranslate nohighlight">\((s_t, a_t, r_t, s_{t+1})\)</span>만으로 바로 네트워크 업데이트가 가능하다. 즉, 매 스탭 <span class="math notranslate nohighlight">\(t\)</span>마다 policy gradient에 대한 추정치 하나가 생긴다.</p>
<div class="math notranslate nohighlight">
\[
\nabla_{\theta} J(\theta) \approx \hat{g}_{\text{online}} := \left( r_t + \gamma  V_{\theta}(s_{t+1}) - V_{\phi}(s_t)\right) \nabla_{\mathbf{\theta}} \log \pi_{\mathbf{\theta}}(a_t | s_t).
\]</div>
<br>
<p>매 스탭마다 실시간으로 구할 수 있는 그레디언트 추정치이기 때문에 <span class="math notranslate nohighlight">\(\hat{g}_{\text{online}}\)</span>라고 적어주었다. 이제 매 스탭마다 정책 네트워크를 업데이트시킬 수 있다.
하지만 REINFORCE with base line의 경우 가치 네트워크 <span class="math notranslate nohighlight">\(V_{\phi}(s_t)\)</span>를 학습시키기 위해서 역시 return을 사용했기 때문에 환경과 상호작용이 종료되어야만 업데이트가 가능했다. 이를 보완하기 위하여 다음 실제 상태가치함수의 재귀적 성질을 이용할 것이다.</p>
<div class="math notranslate nohighlight">
\[V^{\pi}(s)= \mathbb{E}_{a \sim \pi(\cdot|s), s' \sim p(\cdot|s,a)} \left[ r(s, a) + \gamma  V^{\pi}(s')\right] \; \text{ for all } \; s \in \mathcal{S}.\]</div>
<br>
<p>역시나 실제 기댓값을 구할 수 없기 때문에 기댓값 대신 데이터 <span class="math notranslate nohighlight">\((s_t, a_t, r_t, s_{t+1})\)</span>을 이용하고 다음 상태의 상태가치함수를 네트워크를 사용하여 근사시키면 다음과 같은 실제 상태가치함수에 대한 추정치를 얻을 수 있다.</p>
<div class="math notranslate nohighlight">
\[V^{\pi}(s_t) \approx r_t + \gamma  V_{\phi}(s_{t+1}).\]</div>
<br>
<p>이제 <span class="math notranslate nohighlight">\(G_t\)</span>를 레이블로 사용하여 가치 네트워크 <span class="math notranslate nohighlight">\(V_{\phi}(s_{t+1})\)</span>를 학습시키는 대신 <span class="math notranslate nohighlight">\(r_t + \gamma  V_{\phi}(s_{t+1})\)</span>을 레이블 <span class="math notranslate nohighlight">\(y_t\)</span>로 사용하여 <span class="math notranslate nohighlight">\(V_{\phi}(s_{t+1})\)</span>를 학습시킨다. 구현할 때 주의할 점은 레이블로 사용되는 <span class="math notranslate nohighlight">\(y_t=r_t + \gamma  V_{\phi}(s_{t+1})\)</span> 역시 파라미터 <span class="math notranslate nohighlight">\(\phi\)</span>를 포함하고 있다. <span class="math notranslate nohighlight">\(y_t\)</span>는 레이블로만 사용되기 때문에 실제 구현에서는 파이토치의 <code class="docutils literal notranslate"><span class="pre">detach()</span></code> 메서드를 사용하여 <span class="math notranslate nohighlight">\(y_t\)</span>를 상수 취급하고 <span class="math notranslate nohighlight">\(\phi\)</span>에 대한 그레디언트를 계산하지 않는다.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./book/Chapter2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="4-reinforce-with-baseline.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">9. </span>REINFORCE with baseline</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../Reference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">참고문헌</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By 재야의 숨은 초보<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>